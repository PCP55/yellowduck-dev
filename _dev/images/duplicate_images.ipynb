{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T05:26:07.251012Z",
     "start_time": "2020-10-16T05:26:07.235049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check Duplicate Picture in Directory\n",
    "\n",
    "# mode = 'same'\n",
    "# Use Cryptographic hashing algorithms in 'hashlib'\n",
    "# Editing image won't be count as the duplicated image.\n",
    "\n",
    "# mode = 'similar'\n",
    "# Use Perceptual hashing algorithms\n",
    "# Hash value of editing image will be close to the original image.\n",
    "\n",
    "import os\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import numpy as np\n",
    "\n",
    "class duplicate():\n",
    "    #################################################################\n",
    "    # init\n",
    "    def __init__(self, image_folder_path):\n",
    "        \n",
    "\n",
    "        try:\n",
    "            get_ipython\n",
    "            self.current_path = os.getcwd() # For test function in .ipynb\n",
    "        except:\n",
    "            self.current_path = os.path.dirname(os.path.realpath(__file__)) # For .py\n",
    "            \n",
    "        self.current_path = os.path.join(self.current_path, image_folder_path)\n",
    "\n",
    "        self.remove_filename_list = [] # List of similar image except original one\n",
    "        self.similar_group_dict = {} # Group of similar image including original one\n",
    "\n",
    "    #################################################################\n",
    "    # Find    \n",
    "    def find(self, mode = 'same', distance = 0, phash_size = 16):\n",
    "        \n",
    "        num = 0\n",
    "        filename_hash = dict()\n",
    "        image_list = os.listdir(self.current_path)\n",
    "        \n",
    "        ###########################\n",
    "\n",
    "        if mode == 'same':\n",
    "\n",
    "            hash_keys = dict()\n",
    "            duplicate_group = dict()\n",
    "            self.remove_filename_list = []\n",
    "\n",
    "            for index, filename in enumerate(image_list):\n",
    "\n",
    "                file_path = os.path.join(self.current_path, filename)\n",
    "\n",
    "                if os.path.isfile(file_path):\n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        filehash = hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "                    filename_hash[filename] = filehash\n",
    "\n",
    "                    if filehash not in hash_keys:\n",
    "                        hash_keys[filehash] = index\n",
    "                        \n",
    "                    else:\n",
    "                        self.remove_filename_list.append(filename)\n",
    "\n",
    "            set_hash = set(filename_hash.values())\n",
    "\n",
    "            for h in set_hash:\n",
    "                duplicate_group[h] = [k for k in filename_hash.keys() if filename_hash[k] == h]\n",
    "\n",
    "            for val in duplicate_group.values():\n",
    "                if len(val) > 1:\n",
    "                    self.similar_group_dict[num] = val\n",
    "                    num = num + 1\n",
    "\n",
    "            ############\n",
    "            # print\n",
    "\n",
    "            num_duplicate = len(self.remove_filename_list)\n",
    "            num_all = len(filename_hash)\n",
    "            percentage = np.round(num_duplicate/num_all * 100, 2)\n",
    "\n",
    "            print('There are {} duplicated images from {} images which is around {} %.'.format(num_duplicate, num_all,percentage))\n",
    "\n",
    "            return self.remove_filename_list, self.similar_group_dict\n",
    "\n",
    "        ###########################\n",
    "\n",
    "        if mode == 'similar':\n",
    "            \n",
    "            temp_filename_hash = dict()\n",
    "            temp_filename_list = []\n",
    "            self.remove_filename_list = []\n",
    "\n",
    "            print('The accepted distance is {}'.format(distance))\n",
    "            \n",
    "            ############\n",
    "            # Find phash\n",
    "            for filename in image_list:\n",
    "\n",
    "                file_path = os.path.join(self.current_path, filename)\n",
    "                \n",
    "                if os.path.isfile(file_path):\n",
    "                    image_file = Image.open(file_path)                        \n",
    "                    phash = imagehash.phash(image_file, hash_size = phash_size)\n",
    "                    filename_hash[filename] = phash\n",
    "                    temp_filename_hash[filename] = phash\n",
    "            \n",
    "            ############        \n",
    "            # Find similarity between image using hamming distance (of phash)\n",
    "            \n",
    "            sort_filename_hash = sorted(filename_hash)\n",
    "            \n",
    "            for file_first in sort_filename_hash:\n",
    "                \n",
    "                if file_first in temp_filename_hash:\n",
    "                \n",
    "                    temp_similar_list = []\n",
    "                    temp_similar_list.append(file_first)\n",
    "                    temp_filename_list.append(file_first)\n",
    "                    temp_filename_hash.pop(file_first)\n",
    "\n",
    "                    image_first = filename_hash[file_first]\n",
    "                \n",
    "                for file_second in sort_filename_hash:\n",
    "                    \n",
    "                    if file_second not in temp_filename_list:\n",
    "                        \n",
    "                        image_second = filename_hash[file_second]\n",
    "                        \n",
    "                        hamming_distance = image_first - image_second\n",
    "                        \n",
    "                        if hamming_distance <= distance:\n",
    "                            temp_similar_list.append(file_second)\n",
    "                            temp_filename_list.append(file_second)\n",
    "\n",
    "                if len(temp_similar_list) > 1:\n",
    "                    self.similar_group_dict[num] = temp_similar_list\n",
    "\n",
    "                    for _item in temp_similar_list[1:]:\n",
    "                        self.remove_filename_list.append(_item)\n",
    "\n",
    "                    num = num + 1\n",
    "            \n",
    "            ############\n",
    "            # print\n",
    "\n",
    "            num_duplicate = len(self.remove_filename_list)\n",
    "            num_all = len(filename_hash)\n",
    "            percentage = np.round(num_duplicate/num_all * 100, 2)\n",
    "\n",
    "            print('There are {} similar images in distance from {} images which is around {} %.'.format(num_duplicate, num_all,percentage))\n",
    "\n",
    "            return self.remove_filename_list, self.similar_group_dict\n",
    "\n",
    "    #################################################################\n",
    "    # Get           \n",
    "    def get(self):\n",
    "            \n",
    "        return self.similar_group_dict, self.remove_filename_list\n",
    "            \n",
    "                   \n",
    "    #################################################################\n",
    "    # Show    \n",
    "    def show(self, max_sample_case = 1, max_sample_each_case = 1, size = 1):\n",
    "        \n",
    "        try:\n",
    "            get_ipython\n",
    "#             matplotlib show duplicate or similar picture\n",
    "            print(self.similar_group_dict)\n",
    "        except:\n",
    "            print('Please run it in notebook')\n",
    "\n",
    "    #################################################################\n",
    "    # Move \n",
    "    def move_to_folder(self):\n",
    "        pass\n",
    "\n",
    "    #################################################################\n",
    "    # Remove    \n",
    "    def remove_in_folder(self):\n",
    "        for filename in self.remove_filename_list:\n",
    "            file_path = os.path.join(self.current_path, filename)\n",
    "            os.remove(file_path)\n",
    "\n",
    "# Credit: https://medium.com/@urvisoni/removing-duplicate-images-through-python-23c5fdc7479e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-217-d2c2439152e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_list1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_label1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_label1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(5, 5, figsize=(20, 20))\n",
    "\n",
    "col = -1\n",
    "\n",
    "for index, image, wrong, right in zip(range(25), wrong_list1[:25], wrong_label1[:25], right_label1[:25]):\n",
    "    path = os.path.join(training_dir, image)\n",
    "    image = Image.open(path)\n",
    "    row = index%5\n",
    "    if row == 0:\n",
    "        col = col + 1\n",
    "\n",
    "    axs[row,col].imshow(np.array(image))\n",
    "    axs[row,col].set_title('Predict as {}, Actual {}'.format(wrong[0], right))\n",
    "    axs[row,col].grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:49:37.654297Z",
     "start_time": "2020-10-07T11:49:37.639219Z"
    }
   },
   "outputs": [],
   "source": [
    "pic_path = '.\\image_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T05:19:01.759530Z",
     "start_time": "2020-10-16T05:19:01.744514Z"
    }
   },
   "outputs": [],
   "source": [
    "my_dup = duplicate(pic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T05:19:02.800050Z",
     "start_time": "2020-10-16T05:19:02.778058Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 4 duplicated images from 30 images which is around 13.33 %.\n"
     ]
    }
   ],
   "source": [
    "remove_list, similar_group = my_dup.find(mode = 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T05:14:02.007225Z",
     "start_time": "2020-10-16T05:14:01.991238Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['q_copy1.jpg', 'q_copy2.jpg', 'r_copy.jpg', 's_copy.jpg']"
      ]
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": [
    "remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T05:14:47.888364Z",
     "start_time": "2020-10-16T05:14:47.873363Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: ['s.jpg', 's_copy.jpg'],\n",
       " 1: ['q.jpg', 'q_copy1.jpg', 'q_copy2.jpg'],\n",
       " 2: ['r.jpg', 'r_copy.jpg']}"
      ]
     },
     "metadata": {},
     "execution_count": 224
    }
   ],
   "source": [
    "similar_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T05:25:46.148831Z",
     "start_time": "2020-10-16T05:25:45.958799Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The accepted distance is 0\n",
      "There are 4 similar images in distance from 30 images which is around 13.33 %.\n"
     ]
    }
   ],
   "source": [
    "remove_list, similar_group = my_dup.find(mode = 'similar', distance = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['q_copy1.jpg', 'q_copy2.jpg', 'r_copy.jpg', 's_copy.jpg']"
      ]
     },
     "metadata": {},
     "execution_count": 226
    }
   ],
   "source": [
    "remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: ['q.jpg', 'q_copy1.jpg', 'q_copy2.jpg'],\n",
       " 1: ['r.jpg', 'r_copy.jpg'],\n",
       " 2: ['s.jpg', 's_copy.jpg']}"
      ]
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "source": [
    "similar_group"
   ]
  },
  {
   "source": [
    "# Usage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\nCollecting goldfish\n  Downloading https://test-files.pythonhosted.org/packages/96/2b/071d8142c9fa96b85b40fbc08393aba01f2df7dbd1bb156b6809a410958e/goldfish-0.0.3-py3-none-any.whl (5.8 kB)\nInstalling collected packages: goldfish\n  Attempting uninstall: goldfish\n    Found existing installation: goldfish 0.0.2\n    Uninstalling goldfish-0.0.2:\n      Successfully uninstalled goldfish-0.0.2\nSuccessfully installed goldfish-0.0.3\n"
     ]
    }
   ],
   "source": [
    "# Test Pypi\n",
    "\n",
    "# !pip install --upgrade --force-reinstall --index-url https://test.pypi.org/simple/ --no-deps goldfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pypi\n",
    "\n",
    "# !pip install goldfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:30:46.960776Z",
     "start_time": "2020-10-07T11:30:46.243739Z"
    }
   },
   "outputs": [],
   "source": [
    "from goldfish.images.duplicate import duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:31:29.299391Z",
     "start_time": "2020-10-07T11:31:29.283385Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 4 duplicated images from 30 images which is around 13.33 %.\n"
     ]
    }
   ],
   "source": [
    "remove_list, similar_group = duplicate('.\\image_data').find(mode = 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['q_copy1.jpg', 'q_copy2.jpg', 'r_copy.jpg', 's_copy.jpg']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T11:31:40.814459Z",
     "start_time": "2020-10-07T11:31:40.808498Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: ['s.jpg', 's_copy.jpg'],\n",
       " 1: ['q.jpg', 'q_copy1.jpg', 'q_copy2.jpg'],\n",
       " 2: ['r.jpg', 'r_copy.jpg']}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "similar_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The accepted distance is 10\n",
      "There are 5 similar images in distance from 30 images which is around 16.67 %.\n"
     ]
    }
   ],
   "source": [
    "remove_list, similar_group = duplicate('.\\image_data').find(mode = 'similar', distance = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['q_copy1.jpg', 'q_copy2.jpg', 'r_copy.jpg', 's_copy.jpg', 'x_edit2.jpg']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: ['q.jpg', 'q_copy1.jpg', 'q_copy2.jpg'],\n",
       " 1: ['r.jpg', 'r_copy.jpg'],\n",
       " 2: ['s.jpg', 's_copy.jpg'],\n",
       " 3: ['x.jpg', 'x_edit2.jpg']}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "similar_group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}